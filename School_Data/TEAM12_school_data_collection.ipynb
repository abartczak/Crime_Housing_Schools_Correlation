{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to setup data collection for schooldigger.com API\n",
    "It also performs other tasks using Google maps API to get schools latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Get required API key related data'Priv\n",
    "from config import appID, appKey, gkey\n",
    "# Define base URL\n",
    "url = 'https://api.schooldigger.com/v1.2/schools'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to jsonFilePrivate.json\n",
      "{\n",
      "    \"_comment\": \"NOTICE: API limit for Dev/Test is 1 call per minute, up to 20 calls per day. This limit has been reached. You may continue to make calls, but this result is bogus data and should not be used in a production environment. To change your API plan, go to https://developer.schooldigger.com/admin/applications/\",\n",
      "    \"numberOfPages\": 0,\n",
      "    \"numberOfSchools\": 0,\n",
      "    \"schoolList\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define User Parameters before calling the endpoint above to fetch json school data\n",
    "st = 'MN'\n",
    "districtID = '2721240'\n",
    "level = 'Elementary'\n",
    "city = 'Minneapolis'\n",
    "perPage = '50'\n",
    "\n",
    "school_levels = ['Elementary', 'Middle', 'High', 'Alt', 'Private']\n",
    "for level in school_levels:\n",
    "    params = dict(st=st, districtID=districtID, level=level, city=city, perPage=perPage, appID=appID, appKey=appKey)\n",
    "    res = requests.get(url, params=params)\n",
    "    json_resp = res.json()\n",
    "    Wait 2 minutes due to API limitations\n",
    "    time.sleep(120)\n",
    "    try:\n",
    "        with open(f\"./data/json_files/jsonFile{level}.json\", 'w') as file:\n",
    "            json.dump(json_resp, file, ensure_ascii=False)\n",
    "            print(f\"Data written to jsonFile{level}.json\")            \n",
    "    except:\n",
    "        print(\"Something went wrong with saving file\")\n",
    "    print(json.dumps(json_resp, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize series used to collect school data for distinct columns\n",
    "schoolid = []\n",
    "schoolName = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "latlng = []\n",
    "year = []\n",
    "numberOfStudents = []\n",
    "percentFreeDiscLunch = []\n",
    "pupilTeacherRatio = []\n",
    "rankStars = []\n",
    "rankLevel = []\n",
    "rankStatewidePercentage = []\n",
    "averageStandardScore = []\n",
    "neighborhood = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for level in school_levels:\n",
    "    # Load JSON\n",
    "    jsonFileName = f\"./data/json_files/jsonFile{level}.json\"\n",
    "    with open(jsonFileName) as jsonfile:\n",
    "        json_resp = json.load(jsonfile)\n",
    "        #print(json.dumps(json_resp, indent=4, sort_keys=True))    \n",
    "        # Create Json object to extract the relevant data for each school level\n",
    "        schoolList = json_resp[\"schoolList\"]\n",
    "        # Figure out the number of schools in that particular school level category\n",
    "        schoolNum = json_resp[\"numberOfSchools\"]\n",
    "        print(schoolNum)    \n",
    "        for i in range (0, schoolNum):\n",
    "            # Generic school info\n",
    "            schoolid.append(schoolList[i][\"schoolid\"])        \n",
    "            schoolName.append(schoolList[i][\"schoolName\"])\n",
    "            latt = schoolList[i][\"address\"][\"latLong\"][\"latitude\"]\n",
    "            latitude.append(schoolList[i][\"address\"][\"latLong\"][\"latitude\"])\n",
    "            lont = schoolList[i][\"address\"][\"latLong\"][\"longitude\"]          \n",
    "            longitude.append(schoolList[i][\"address\"][\"latLong\"][\"longitude\"])\n",
    "            latlngt = f\"{latt}, {lont}\"\n",
    "            latlng.append(latlngt)\n",
    "            # School details - these fields were present in all datasets\n",
    "            year.append(schoolList[i][\"schoolYearlyDetails\"][0][\"year\"])        \n",
    "            numberOfStudents.append(schoolList[i][\"schoolYearlyDetails\"][0][\"numberOfStudents\"])\n",
    "            percentFreeDiscLunch.append(schoolList[i][\"schoolYearlyDetails\"][0][\"percentFreeDiscLunch\"])\n",
    "            pupilTeacherRatio.append(schoolList[i][\"schoolYearlyDetails\"][0][\"pupilTeacherRatio\"])\n",
    "            # Rank History data was missing from various datasets - it needs to be handled separarely\n",
    "            # Look for an empty section for a rankHistory section that is normally a dictionary\n",
    "            if schoolList[i][\"rankHistory\"] is None:\n",
    "                rankStars.append(\"NA\")\n",
    "                rankLevel.append(\"NA\")\n",
    "                rankStatewidePercentage.append(\"NA\")\n",
    "                averageStandardScore.append(\"NA\")\n",
    "            else:\n",
    "                rankStars.append(schoolList[i][\"rankHistory\"][0][\"rankStars\"])\n",
    "                rankLevel.append(schoolList[i][\"rankHistory\"][0][\"rankLevel\"])\n",
    "                rankStatewidePercentage.append(schoolList[i][\"rankHistory\"][0][\"rankStatewidePercentage\"])\n",
    "                averageStandardScore.append(schoolList[i][\"rankHistory\"][0][\"averageStandardScore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{schoolid} {schoolName} {latitude} {longitude} {latlng} {year} {rankStars} {rankLevel} {rankStatewidePercentage} \\\n",
    "    {averageStandardScore} {numberOfStudents} {percentFreeDiscLunch} {pupilTeacherRatio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base URL\n",
    "url = 'https://maps.googleapis.com/maps/api/geocode/json'url\n",
    "\n",
    "# User params specific to all calls to this endpoint above\n",
    "for lat_lng in latlng:\n",
    "    params = dict(latlng=lat_lng, key=gkey)\n",
    "    res = requests.get(url, params=params)\n",
    "    # Delay processing by five seconds due to API provider restrictions on usage\n",
    "    time.sleep(5)\n",
    "    json_resp = res.json()\n",
    "    json_resp_tmp = json_resp['results'][0]['address_components'][2]['long_name']\n",
    "    neighborhood.append(json_resp_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{schoolid} {schoolName} {latitude} {longitude} {latlng} {year} {rankStars} {rankLevel} {rankStatewidePercentage} \\\n",
    "    {averageStandardScore} {numberOfStudents} {percentFreeDiscLunch} {pupilTeacherRatio} {neighborhood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine individual series above to create a dataframe consisting of all of them\n",
    "minneapolis_schools = {'School ID': schoolid, 'School Name': schoolName, 'Latitude Longitude': latlng, 'Student Population': numberOfStudents,\n",
    "                  'Free Discount Lunch': percentFreeDiscLunch, 'Students Per Teacher': pupilTeacherRatio, 'Rank Stars': rankStars, \n",
    "                  'Rank Level': rankLevel, 'Rank Statewide': rankStatewidePercentage, 'Average Standard Score': averageStandardScore,\n",
    "                  'Neighborhood': neighborhood}\n",
    "# Combine individual series above to create a dataframe consisting of all of them\n",
    "minneapolis_schools = {'School ID': schoolid, 'School Name': schoolName, 'Latitude Longitude': latlng, 'Student Population': numberOfStudents,\n",
    "                  'Free Discount Lunch': percentFreeDiscLunch, 'Students Per Teacher': pupilTeacherRatio, 'Rank Stars': rankStars, \n",
    "                  'Rank Level': rankLevel, 'Rank Statewide': rankStatewidePercentage, 'Average Standard Score': averageStandardScore,\n",
    "                  'Neighborhood': neighborhood}\n",
    "\n",
    "minneapolis_schools_df = pd.DataFrame(minneapolis_schools)  \n",
    "minneapolis_schools_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CSV file\n",
    "output_data_file = \"data/csv_files/minneapolis_schools.csv\"\n",
    "# Output data to an Excel CSV file\n",
    "minneapolis_schools_df.to_csv(output_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concluded data collection efforts from two API services. Each had specific restriction relating to the \n",
    "number of call per minutes and the total daily usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
